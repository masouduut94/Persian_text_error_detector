word_embeddings:
  # Two types of word embedding algorithm (word2vec and glove) are supported. :)
  # Just set the default to empty string to disable the word embeddings
  default:
  word2vec:
    path: data/give/glove/vec.npy
    dimension: 1
    binary: True
  glove:
    path: ../../data/glove/word2id.txt
    dimension: 100
    length: 400000

datasets:
  # Support currently 3 datasets: mrpolarity, 20newsgroup and localdata
  default: persian
  mrpolarity:
    positive_data_file:
      path: "data/rt-polaritydata/rt-polarity.pos"
      info: "Data source for the positive data"
    negative_data_file:
      path: "data/rt-polaritydata/rt-polarity.neg"
      info: "Data source for the negative data"
  persian:
    add:
      path: "data/20newsgroup/train/add/add.txt"
      info: "Data source for the positive data"
    noerror:
      path: "data/20newsgroup/train/noerror/noerror.txt"
      info: "Data source for the negative data"
    remove:
      path: "data/20newsgroup/train/remove/remove.txt"
      info: "Data source for the negative data"
    replace:
      path: "data/20newsgroup/train/replace/replace.txt"
      info: "Data source for the negative data"
    zamir:
      path: "data/20newsgroup/train/zamir/zamir.txt"
      info: "Data source for the negative data"

  20newsgroup:
    # The dataset includes following 20 newsgroups:
    # alt.atheism, comp.windows.x, rec.sport.hockey, soc.religion.christian
    # comp.graphics, misc.forsale, sci.crypt, talk.politics.guns
    # comp.os.ms-windows.misc, rec.autos, sci.electronics, talk.politics.mideast
    # comp.sys.ibm.pc.hardware, rec.motorcycles, sci.med, talk.politics.misc
    # comp.sys.mac.hardware, rec.sport.baseball, sci.space, talk.religion.misc
    categories:
      - add
      - remove
      - replace
      - zamir
      - noerror
    shuffle: True
    random_state: 42
  localdata:
    # Load text files with categories as subfolder names.
    # Individual samples are assumed to be files stored
    # a two levels folder structure such as the following:
    # container_folder/
    #   category_1_folder/
    #     file_1.txt file_2.txt ... file_42.txt
    #   category_2_folder/
    #     file_43.txt file_44.txt ...
    #
    # As an example, a SentenceCorpus dataset from
    # https://archive.ics.uci.edu/ml/datasets/Sentence+Classification
    # has been used. The dataset includes following 3 domains:
    # arxiv, jdm and plos
    container_path: ../../data/input/SentenceCorpus
    categories:
    shuffle: True
    random_state: 42

  testdata:
    container_path: ./data/t2
    categories:
      - add
      - remove
      - replace
      - zamir
      - noerror

      
   